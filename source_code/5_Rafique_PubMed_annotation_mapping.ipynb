{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de75f923",
   "metadata": {},
   "source": [
    "# Annotate the leftover variants from Rafique table using PubMed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fa6da1",
   "metadata": {},
   "source": [
    "## 1. Select the unannotated variants from the annotated Rafique table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002cac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Rafique_annotated = pd.read_csv('Rafique_with_rs.csv', \n",
    "                                converters={i: str for i in range(11)}, low_memory=False)\n",
    "Rafique_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_without_nan = []\n",
    "for item in Rafique_annotated['ensembl_id']:\n",
    "    if str(item).startswith('rs'): \n",
    "        ids_without_nan.append(item)\n",
    "    else: \n",
    "        item = ''\n",
    "        ids_without_nan.append(item)  \n",
    "Rafique_annotated['ensembl_id'] = ids_without_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_var_Rafique = Rafique_annotated[Rafique_annotated['ensembl_id'] == ''].reset_index(drop=True)\n",
    "leftover_var_Rafique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc121081",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_var_Rafique.to_csv(\n",
    "    'Rafique_without_rs.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of references to extract PMIDS\n",
    "\n",
    "ref_list = []\n",
    "for ref in leftover_var_Rafique['Reference']:\n",
    "    if '-' in ref:\n",
    "        norm_ref = ref[1:]\n",
    "        ref_list.append(norm_ref)\n",
    "    if '(' in ref:\n",
    "        for x in re.findall('[0-9]+', ref):\n",
    "            ref_list.append(x)\n",
    "\n",
    "left_refs_int = [eval(i) for i in list(set(ref_list))]\n",
    "left_refs_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(left_refs_int).to_csv(\n",
    "    'leftover_refs.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099cc07",
   "metadata": {},
   "source": [
    "## 2. Take the bibliography from Rafique and extract paper titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161be965",
   "metadata": {},
   "source": [
    "Take the bibliography from Supplementary 2, it is not the same as in the paper!\n",
    "Create a dataframe with tites and their numbers in bibliography to match to the numbers in the supplimentary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibliography = open(\n",
    "    'input/references_Rafique.txt').readlines()\n",
    "clean_bibliography = []\n",
    "for line in bibliography:\n",
    "    clean_bibliography.append(line.replace('[', '').replace(']', '').replace('?', '.').replace('!', '.'))\n",
    "columns = ['number', 'title']\n",
    "df_data = []\n",
    "for line in clean_bibliography:\n",
    "    number = line.split('.')[0]\n",
    "    title = ' '.join(line.split('.')[2:-3])\n",
    "    df_data.append([number, title])\n",
    "number_titles = pd.DataFrame(data=df_data, columns=columns)\n",
    "number_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_titles.to_csv(\n",
    "    'whole_pipeline_311022/bibliography_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d752e2",
   "metadata": {},
   "source": [
    "Query PubMed API to get PMIDs based og the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'number':[], 'PMID':[]}\n",
    "#results_list = []\n",
    "db = 'pubmed'\n",
    "domain = 'https://www.ncbi.nlm.nih.gov/entrez/eutils'\n",
    "nresults = 10\n",
    "for index,row in number_titles.iterrows():\n",
    "    query = row['title']\n",
    "    number = row['number'] #pass the numbers to the results to know where is what\n",
    "    retmode='json'\n",
    "    # standard query\n",
    "    queryLinkSearch = f'{domain}/esearch.fcgi?db={db}&retmax={nresults}&retmode={retmode}&term={query}'\n",
    "    response = requests.get(queryLinkSearch)\n",
    "    \n",
    "    #extract the idlists and add them to the dataframe along with the numbers\n",
    "    result_json = response.json()\n",
    "    \n",
    "    PMID = result_json['esearchresult']['idlist']   \n",
    "    result_dict['number'].append(number)\n",
    "    result_dict['PMID'].append(PMID)\n",
    "\n",
    "    time.sleep(1)\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb50724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PMIDs = pd.DataFrame(result_dict)\n",
    "PMIDs['title'] = number_titles['title']\n",
    "PMIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMIDs.to_csv('PMIDs_queried.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a356222",
   "metadata": {},
   "source": [
    "Unfortunately, a lot of IDs have not been sucsessfully fetched, so one needs to look them up and add them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMIDs_curated = pd.read_csv('input/PMIDs_curated.csv')\n",
    "justIDs = []\n",
    "for i in PMIDs_curated['PMID']:\n",
    "    justIDs.append(i[2:-2])\n",
    "PMIDs_curated['PMID'] = justIDs\n",
    "PMIDs_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter PMIDs to the ones left over from the mapping\n",
    "leftover_IDs = PMIDs_curated.query('number in @left_refs_int').reset_index(drop=True)\n",
    "leftover_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210cae26",
   "metadata": {},
   "source": [
    "Fetch variants with Ensembl API: takes PMID and returns rs identifiers of the variants reported in those papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_IDs = []\n",
    "PMID_mapping = []\n",
    "passed_IDs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a241bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "server = \"https://rest.ensembl.org\"\n",
    "\n",
    "for ID in leftover_IDs['PMID']:\n",
    "    if ID not in passed_IDs:\n",
    "        ext = \"/variation/human/pmid/\" + str(ID) + \"?\"\n",
    "        r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    "        if not r.ok:\n",
    "            print(\"bad\" + str(ID))\n",
    "            bad_IDs.append(ID)\n",
    "            continue\n",
    "        var_decoded = r.json()\n",
    "        rs_list = []\n",
    "        for variant in var_decoded:\n",
    "            rs_list.append(variant['name'])\n",
    "        PMID_mapping.append({'PMID': ID, 'rs': rs_list})\n",
    "        time.sleep(1)\n",
    "        print(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMID_mapping_df = pd.DataFrame(PMID_mapping)\n",
    "PMID_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883387d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMID_mapping_df.to_csv(\n",
    "    'extracted_rs_with_PMIDs_Rafique.csv',\n",
    "    header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02289417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of extracted rs\n",
    "rs_list = []\n",
    "for item in PMID_mapping_df['rs']:\n",
    "    for rs in item:\n",
    "        rs_list.append(rs)\n",
    "len(rs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2478b",
   "metadata": {},
   "source": [
    "Map the extracted variants to the reference Ensembl table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_Ens = pd.read_csv(\n",
    "    'Ens_filtered_all_alleles_location_coord_no_duplicates.csv'\n",
    "    , converters={'alleles': ast.literal_eval}, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d288a6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering the Ensembl table to only those variants\n",
    "mapped_variants = ref_Ens.drop_duplicates().query('id in @rs_list').reset_index(drop=True)\n",
    "mapped_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ceb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to file specifying that it is the 2nd stage of annotation\n",
    "mapped_variants.to_csv(\n",
    "    'Rafique_mapped_to_Ens_2nd.csv',\n",
    "    header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53587d",
   "metadata": {},
   "source": [
    "## 3. Dealing with bad IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a373116",
   "metadata": {},
   "source": [
    "Which PMIDs did not return any variants and which references are this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b5bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11ea74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_ref = []\n",
    "for index,row in leftover_IDs.iterrows():\n",
    "    if row['PMID'] in bad_IDs:\n",
    "        bad_ref.append(row['number'])\n",
    "bad_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f85b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leftover_var_Rafique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcaf67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add a new column with references as list items\n",
    "ref_list_new_column = []\n",
    "for ref in leftover_var_Rafique['Reference']:\n",
    "    \n",
    "    if '-' in ref:\n",
    "        norm_ref = [int(ref[1:])]\n",
    "        ref_list_new_column.append(norm_ref)\n",
    "        \n",
    "    elif '(' in ref:\n",
    "        ref_list_new_column.append(ref.replace('(', '').replace(')', '').split(', '))\n",
    "        \n",
    "    else: ref_list_new_column.append([])\n",
    "ref_list_new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_var_Rafique['Reference_lists'] = ref_list_new_column\n",
    "leftover_var_Rafique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d494842",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for index, row in leftover_var_Rafique.iterrows():\n",
    "    for bad_reference in bad_ref:\n",
    "        if bad_reference in row['Reference_lists']:\n",
    "            index_list.append(index)\n",
    "Rafique_var_for_manual_rescue = leftover_var_Rafique[leftover_var_Rafique.index.isin(index_list)].reset_index(drop=True)\n",
    "Rafique_var_for_manual_rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rafique_var_for_manual_rescue.to_csv(\n",
    "    'Rafique_var_for_manual_rescue.csv',\n",
    "    header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
